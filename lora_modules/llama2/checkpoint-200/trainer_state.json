{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1,
      "grad_norm": 2.881974458694458,
      "learning_rate": 0.000979381443298969,
      "loss": 1.2622,
      "step": 10
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.9737155437469482,
      "learning_rate": 0.0009278350515463918,
      "loss": 1.1039,
      "step": 20
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.0310142040252686,
      "learning_rate": 0.0008762886597938144,
      "loss": 1.3348,
      "step": 30
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0673394203186035,
      "learning_rate": 0.000824742268041237,
      "loss": 1.0401,
      "step": 40
    },
    {
      "epoch": 0.5,
      "grad_norm": 5.061291217803955,
      "learning_rate": 0.0007731958762886599,
      "loss": 1.1853,
      "step": 50
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9206743240356445,
      "learning_rate": 0.0007216494845360825,
      "loss": 1.0244,
      "step": 60
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.3020589351654053,
      "learning_rate": 0.0006701030927835051,
      "loss": 1.0913,
      "step": 70
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.6706414222717285,
      "learning_rate": 0.0006185567010309279,
      "loss": 1.2452,
      "step": 80
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.7083320617675781,
      "learning_rate": 0.0005670103092783505,
      "loss": 0.9369,
      "step": 90
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.517428159713745,
      "learning_rate": 0.0005154639175257731,
      "loss": 1.1305,
      "step": 100
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.7425203323364258,
      "learning_rate": 0.0004639175257731959,
      "loss": 0.7505,
      "step": 110
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.3078765869140625,
      "learning_rate": 0.0004123711340206185,
      "loss": 0.7907,
      "step": 120
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.8290010690689087,
      "learning_rate": 0.00036082474226804123,
      "loss": 0.8915,
      "step": 130
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.7545671463012695,
      "learning_rate": 0.00030927835051546395,
      "loss": 0.6431,
      "step": 140
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.1992695331573486,
      "learning_rate": 0.00025773195876288655,
      "loss": 0.7302,
      "step": 150
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.215711236000061,
      "learning_rate": 0.00020618556701030926,
      "loss": 0.6755,
      "step": 160
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.003180503845215,
      "learning_rate": 0.00015463917525773197,
      "loss": 0.5832,
      "step": 170
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.1934783458709717,
      "learning_rate": 0.00010309278350515463,
      "loss": 0.9101,
      "step": 180
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.4460644721984863,
      "learning_rate": 5.1546391752577315e-05,
      "loss": 0.62,
      "step": 190
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.7714157104492188,
      "learning_rate": 0.0,
      "loss": 0.6285,
      "step": 200
    }
  ],
  "logging_steps": 10,
  "max_steps": 200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 620580505411584.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
